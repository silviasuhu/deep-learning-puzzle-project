{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836b4f19",
   "metadata": {},
   "source": [
    "# Inference and visualization for DiffAssemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ef19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image, ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22829c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.full_models import *\n",
    "from src.full_dataset import *\n",
    "from src.gnn_diffusion import GNN_Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1c51f",
   "metadata": {},
   "source": [
    "### 0.- Define paths and steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.getcwd(), \"data/CelebA-HQ\")\n",
    "print(dataset_path)\n",
    "\n",
    "steps = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192833c6",
   "metadata": {},
   "source": [
    "### 1.- Load test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed9421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base dataset\n",
    "test_dataset_base = CelebA_HQ(dataset_path, train=False)\n",
    "print(f\"Test dataset length: {len(test_dataset_base)}\")\n",
    "print(f\"Sample image: \")\n",
    "plt.imshow(test_dataset_base[0])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420366a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load puzzle dataset and sample an element\n",
    "test_puzzle_dt = Puzzle_Dataset_ROT(\n",
    "                        dataset=test_dataset_base,\n",
    "                        patch_per_dim=[(6,6)], \n",
    "                        augment=False, \n",
    "                        degree=-1, \n",
    "                        unique_graph=None, \n",
    "                        all_equivariant=False, \n",
    "                        random_dropout=False)\n",
    "\n",
    "elem = test_puzzle_dt[0]\n",
    "\n",
    "print(elem)\n",
    "print(f\"X: {elem.x}\") # This contains all the node features: x, y, rot1, rot2\n",
    "print(f\"EDGE_INDEX: {elem.edge_index}\")\n",
    "print(f\"INDEXES: {elem.indexes}\")\n",
    "print(f\"ROT: {elem.rot}\")\n",
    "print(f\"ROT_INDEX: {elem.rot_index}\")\n",
    "print(f\"IND_NAME: {elem.ind_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7f5b3",
   "metadata": {},
   "source": [
    "### Load model with the checkpoint from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "model = Eff_GAT(steps=2,\n",
    "                input_channels=4,\n",
    "                output_channels=4,\n",
    "                n_layers=4,\n",
    "                model=\"resnet18equiv\",\n",
    "                architecture=\"transformer\")\n",
    "\n",
    "# Load model with the checkpoint and set to evaluation mode\n",
    "checkpoint = torch.load(\"checkpoints/eff_gat_epoch_30_steps_2_batchsize_10_puzzdim_6_6.pt\",\n",
    "                        weights_only=False,\n",
    "                        map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "print(\"Model parameters after loading checkpoint:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acbe7fe",
   "metadata": {},
   "source": [
    "### Run inference with a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add test step to the GNN Diffusion class\n",
    "# Modify to return noise and predicted noise AND work with batches of size = 1 in a controlled manner\n",
    "class GNN_Diffusion_Inference(GNN_Diffusion):\n",
    "    \n",
    "    def inference_step(self, sample, model, criterion):\n",
    "        sample = sample.to(self.device)\n",
    "\n",
    "        if not sample.batch:\n",
    "            sample.batch = torch.zeros(sample.x.size(0), dtype=torch.long, device=self.device)\n",
    "        \n",
    "        print(sample.batch)\n",
    "\n",
    "        num_graphs = int(sample.batch.max().item()) + 1\n",
    "        t_graph = torch.randint(0, self.steps, (num_graphs,), device=self.device).long()\n",
    "        t = torch.gather(t_graph, 0, sample.batch)\n",
    "\n",
    "        x_start = sample.x\n",
    "        noise = torch.randn_like(x_start)\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
    "\n",
    "        patch_feats = model.visual_features(sample.patches)\n",
    "        prediction, _ = model.forward_with_feats(\n",
    "            x_noisy, t, sample.patches, sample.edge_index, patch_feats, sample.batch\n",
    "        )\n",
    "        return criterion(noise, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c84bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test_puzzle_dt, batch_size=1, shuffle=False)\n",
    "sample = test_puzzle_dt[0]\n",
    "print(f\"X: {sample.x}\") # This contains all the node features: x, y, rot1, rot2\n",
    "print(f\"EDGE_INDEX: {sample.edge_index}\")\n",
    "print(f\"INDEXES: {sample.indexes}\")\n",
    "print(f\"ROT: {sample.rot}\")\n",
    "print(f\"ROT_INDEX: {sample.rot_index}\")\n",
    "print(f\"IND_NAME: {sample.ind_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load criterion, inference GNN Diffusion class, and run inference step\n",
    "criterion = torch.nn.functional.smooth_l1_loss\n",
    "gnn_diffusion = GNN_Diffusion_Inference(steps=steps)\n",
    "\n",
    "with torch.no_grad():\n",
    "    #This only returns loss, we need to modify to return noise and predicted noise for visualization\n",
    "    loss = gnn_diffusion.inference_step(sample, model, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6410574",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "puzzle-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
