{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347328e3",
   "metadata": {},
   "source": [
    "# Run inference\n",
    "\n",
    "This runs an inference/forward step on a non-training, non-validation dataset and returns:\n",
    "\n",
    " - Individual accuracy for translation and rotation for each batch\n",
    " - Global accuracy for translation and rotation the whole set\n",
    "\n",
    " Requires:\n",
    "\n",
    " - Test dataset path\n",
    " - Model checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b6039",
   "metadata": {},
   "source": [
    "## 0.- Load modules + Set paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from src.model.full_models import *\n",
    "from src.full_dataset import *\n",
    "from src.gnn_diffusion import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c14f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and model paths\n",
    "dataset_path = os.path.join(os.getcwd(), \"data/CelebA-HQ\")\n",
    "model_checkpoint = \"model_epoch90.pt\"\n",
    "\n",
    "# Model variables\n",
    "visual_model = \"resnet18equiv\" # Same as training!\n",
    "gnn_model = \"transformer\" # Same as training!\n",
    "\n",
    "# Variables for inference\n",
    "steps = 100 # Check it's the same as training\n",
    "dims = 6 # Ideally should be the same as training, but can be different for testing\n",
    "batch_size = 16 # Adjust based on GPU memory\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Set up:\\n{'--'*len(dataset_path)}\", flush=True)\n",
    "print(f\"Dataset path: {dataset_path}\", flush=True)\n",
    "print(f\"Model checkpoint: {model_checkpoint}\", flush=True)\n",
    "print(f\"Visual model: {visual_model}\", flush=True)\n",
    "print(f\"Attention GNN model: {gnn_model}\", flush=True)\n",
    "print(f\"Diffusion steps to run: {steps}\", flush=True)\n",
    "print(f\"Puzzle size: {dims}x{dims}\", flush=True)\n",
    "print(f\"Batch size: {batch_size}\", flush=True)\n",
    "print(f\"Using device: {device}\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f99b81f",
   "metadata": {},
   "source": [
    "## 1.- Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base dataset\n",
    "test_dataset_base = CelebA_HQ(dataset_path, train=False)\n",
    "\n",
    "# Create puzzle dataset\n",
    "# Load puzzle dataset and sample an element\n",
    "test_puzzle_dt = Puzzle_Dataset(\n",
    "                        dataset=test_dataset_base,\n",
    "                        patch_per_dim=[(dims,dims)], \n",
    "                        augment=False, \n",
    "                        degree=-1, \n",
    "                        unique_graph=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfe42cb",
   "metadata": {},
   "source": [
    "## 2.- Load model with checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c905f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "model = Eff_GAT(steps=steps,\n",
    "                input_channels=4,\n",
    "                output_channels=4,\n",
    "                n_layers=4,\n",
    "                model=visual_model,\n",
    "                architecture=gnn_model)\n",
    "\n",
    "# Send model to device\n",
    "model.to(device)\n",
    "\n",
    "# Load model with the checkpoint and set to evaluation mode\n",
    "checkpoint = torch.load(f\"checkpoints/{model_checkpoint}\",\n",
    "                        weights_only=False,\n",
    "                        map_location=device)\n",
    "\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "print(\"Model parameters after loading checkpoint:\", flush=True)\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param, flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422614c0",
   "metadata": {},
   "source": [
    "## 3.- Run inference for the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ea911",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader for inference\n",
    "test_loader = torch_geometric.loader.DataLoader(test_puzzle_dt, \n",
    "                                                batch_size=batch_size, \n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a76816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add rotational info for the model to work\n",
    "def add_rot(batch):\n",
    "    # Add/force \"no rotation\" feature [1, 0] for every node in the batch\n",
    "    N = batch.x.size(0)  # total nodes across all graphs in batch\n",
    "    rot = torch.zeros(N, 2, dtype=batch.x.dtype, device=batch.x.device)\n",
    "    rot[:, 0] = 1.0\n",
    "\n",
    "    if batch.x.size(1) == 2:\n",
    "        batch.x = torch.cat([batch.x, rot], dim=1)   # [N,4]\n",
    "    else:\n",
    "        batch.x[:, 2:4] = rot                        # overwrite existing rot channels\n",
    "\n",
    "    batch.rot = rot\n",
    "    batch.rot_index = torch.zeros(N, dtype=torch.long, device=batch.x.device)\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Prepare diffusion model\n",
    "gnn_diffusion = GNN_Diffusion(steps=steps)\n",
    "\n",
    "# same schedule as in GNN_Diffusion\n",
    "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "betas = linear_beta_schedule(timesteps=steps).to(device)\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
    "\n",
    "# Initialize lists to store metrics for each batch\n",
    "test_pos = []\n",
    "test_rot = []\n",
    "test_acc_pos = []\n",
    "test_rot_acc = []\n",
    "\n",
    "# Disable gradient tracking (save memory,prevents accidental backprop)\n",
    "with torch.no_grad():\n",
    "    for i,batch in enumerate(test_loader):\n",
    "        # Print info\n",
    "        print(f\"Processing batch num {i}/{len(test_loader)} with batch_size {batch.batch.max().item()+1}\", flush=True)\n",
    "        \n",
    "        # Add rotation dimensions and send batch to device\n",
    "        batch = add_rot(batch).to(device)\n",
    "        \n",
    "        # Get num batches (graphs) in the current batch of data\n",
    "        num_graphs = int(batch.batch.max().item()) + 1\n",
    "        \n",
    "        # CNN features from image patches\n",
    "        patch_feats = model.visual_features(batch.patches)\n",
    "\n",
    "        # Initial, clean pose\n",
    "        x_start = batch.x\n",
    "        \n",
    "        # Start from pure noise\n",
    "        x_t = torch.randn_like(batch.x)\n",
    "        \n",
    "        # Run step-wise inference\n",
    "        for t_scalar in reversed(range(steps)):       \n",
    "        \n",
    "            t_graph = torch.full((num_graphs,), t_scalar, device=gnn_diffusion.device, dtype=torch.long)\n",
    "            t = t_graph[batch.batch]  # node-level timestep\n",
    "\n",
    "            pred_noise, _ = model.forward_with_feats(\n",
    "                x_t, t, batch.patches, batch.edge_index, patch_feats, batch.batch\n",
    "            )\n",
    "\n",
    "            # Extract scalars for current timestep t\n",
    "            a_t = alphas[t].unsqueeze(-1)\n",
    "            ab_t = alphas_cumprod[t].unsqueeze(-1)\n",
    "            b_t = betas[t].unsqueeze(-1)\n",
    "\n",
    "            z = torch.randn_like(x_t) if t_scalar > 0 else torch.zeros_like(x_t)\n",
    "\n",
    "            # DDPM reverse step: x_t -> x_{t-1}\n",
    "            x_t = (1.0 / torch.sqrt(a_t)) * (\n",
    "                x_t - ((1.0 - a_t) / torch.sqrt(1.0 - ab_t + 1e-8)) * pred_noise\n",
    "            ) + torch.sqrt(b_t) * z\n",
    "            \n",
    "        # At the end of the diffusion process, x_t should be the predicted clean pose\n",
    "        x_0 = x_t \n",
    "        # Get position and rotation of the predicted and ground truth poses\n",
    "        gt_pos, gt_rot = split_pose(x_start)\n",
    "        pred_pos, pred_rot = split_pose(x_0)\n",
    "\n",
    "        # Compute metrics\n",
    "        pos_err = position_error(pred_pos, gt_pos)\n",
    "        rot_err = rotation_error(pred_rot, gt_rot)\n",
    "        acc_pos = piece_position_accuracy(pred_pos, gt_pos)\n",
    "        acc_rot = piece_rotation_accuracy(pred_rot, gt_rot)\n",
    "        \n",
    "        # Append metrics\n",
    "        test_pos.append(pos_err.cpu().numpy())\n",
    "        test_rot.append(rot_err.cpu().numpy())\n",
    "        test_acc_pos.append(acc_pos.cpu().numpy())\n",
    "        test_rot_acc.append(acc_rot.cpu().numpy())\n",
    "        \n",
    "        print(f\"Batch {i} - Position error: {pos_err:.4f}, \\\n",
    "                Rotation error: {rot_err:.4f}, \\\n",
    "                Position accuracy: {acc_pos:.4f}, \\\n",
    "                Rotation accuracy: {acc_rot:.4f}\",\n",
    "                flush=True)\n",
    "\n",
    "    \n",
    "    # Average metrics\n",
    "    test_pos_mean = np.mean(test_pos)\n",
    "    test_rot_mean = np.mean(test_rot)\n",
    "    test_acc_pos_mean = np.mean(test_acc_pos)\n",
    "    test_rot_acc_mean = np.mean(test_rot_acc)\n",
    "    \n",
    "    test_pos_std = np.std(test_pos)\n",
    "    test_rot_std = np.std(test_rot)\n",
    "    test_acc_pos_std = np.std(test_acc_pos)\n",
    "    test_rot_acc_std = np.std(test_rot_acc)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcde184",
   "metadata": {},
   "source": [
    "## 4.- Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bed372",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/inference_results.txt\", \"w\") as f:\n",
    "    f.write(f\"Set up:\\n{'--'*len(dataset_path)}\\n\")\n",
    "    f.write(f\"Dataset path: {dataset_path}\\n\")\n",
    "    f.write(f\"Number of test samples: {len(test_puzzle_dt)}\\n\")\n",
    "    f.write(f\"Number of batches: {len(test_loader)}\\n\")\n",
    "    f.write(f\"Model checkpoint: {model_checkpoint}\\n\")\n",
    "    f.write(f\"Visual model: {visual_model}\\n\")\n",
    "    f.write(f\"Attention GNN model: {gnn_model}\\n\")\n",
    "    f.write(f\"Diffusion steps to run: {steps}\\n\")\n",
    "    f.write(f\"Puzzle size: {dims}x{dims}\\n\")\n",
    "    f.write(f\"Batch size: {batch_size}\\n\")\n",
    "    f.write(f\"Using device: {device}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n\\nInference results:\\n{'--'*len(dataset_path)}\\n\")\n",
    "    f.write(f\"Average position error: {test_pos_mean:.4f}\\n\")\n",
    "    f.write(f\"Standard deviation of position error: {test_pos_std:.4f}\\n\")\n",
    "    f.write(f\"Average rotation error: {test_rot_mean:.4f}\\n\")\n",
    "    f.write(f\"Standard deviation of rotation error: {test_rot_std:.4f}\\n\")\n",
    "    f.write(f\"Average position accuracy: {test_acc_pos_mean:.4f}\\n\")\n",
    "    f.write(f\"Standard deviation of position accuracy: {test_acc_pos_std:.4f}\\n\")\n",
    "    f.write(f\"Average rotation accuracy: {test_rot_acc_mean:.4f}\\n\")   \n",
    "    f.write(f\"Standard deviation of rotation accuracy: {test_rot_acc_std:.4f}\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "puzzle-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
