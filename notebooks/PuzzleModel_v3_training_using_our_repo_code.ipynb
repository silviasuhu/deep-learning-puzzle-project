{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup variables\n",
        "\n",
        "Define the main variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set this to True if this notebook runs in Colab and GPU is enabled.\n",
        "# This variable will be ignored if you're not in Colab\n",
        "GPU_IS_ENABLED_IN_COLAB = True\n",
        "\n",
        "# Enable/Disable Wandb\n",
        "# When enabled, you'll need to login to Wandb through a terminal before running this notebook.\n",
        "# To login to Wandb, run the command 'wandb login' in you terminal.\n",
        "WANDB_DISABLED = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set all the variables as environment variable to be seen by bash scripts\n",
        "\n",
        "os.environ[\"GPU_IS_ENABLED_IN_COLAB\"] = \"1\" if GPU_IS_ENABLED_IN_COLAB else \"0\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\" if WANDB_DISABLED else \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "print(IN_COLAB)\n",
        "\n",
        "# Set IN_COLAB as an environment variable to be seen by bash scripts\n",
        "os.environ[\"IN_COLAB\"] = \"1\" if IN_COLAB else \"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify your python version.\n",
        "Note that this notebook has been tested with python version 3.12.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "âš  Install the required packages only if this notebook runs in Colab. Otherwise you should install the required packages manually on your local python environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install the version 2.6.0 of torch version to be able to install later compatible pytorch-geometric packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  !pip uninstall -y torch torchvision torchaudio\n",
        "  if GPU_IS_ENABLED_IN_COLAB:\n",
        "    !pip install -q torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu126\n",
        "  else:\n",
        "    !pip install -q torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if IN_COLAB:\n",
        "  torch_version = torch.__version__.split('+')[0]\n",
        "  if GPU_IS_ENABLED_IN_COLAB:\n",
        "    cuda_version = torch.version.cuda.replace('.', '')\n",
        "    !pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-{torch_version}+cu{cuda_version}.html\n",
        "\n",
        "  else:\n",
        "    !pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-{torch_version}+cpu.html\n",
        "\n",
        "  !pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not WANDB_DISABLED:\n",
        "    !wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect runtime default versions and settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29RVK7PVTwRw"
      },
      "source": [
        "Check torch and torchvision default versions. For now we are just going to use them, we'll change them if we hit any conflict in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "print(\"\")\n",
        "print(f\"Torch cuda is available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If cuda is not available, enable GPU in Colab by going to 'Runtime' > 'Change runtime type' > Select 'T4 GPU'.\n",
        "\n",
        "This will restart the session and you'll need to rerun all the cells again. After restarting the session, verify that cuda is available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Nvidia version\n",
        "\n",
        "The following command (nvidia-smi) will tell you which GPU you are using (if any)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enable cuda if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import our code\n",
        "\n",
        "Import the classes of the deep-learning-puzzle-project repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "if [ \"$IN_COLAB\" == \"0\" ]; then\n",
        "  echo \"Skipping download (IN_COLAB is false)\"\n",
        "  exit 0\n",
        "fi\n",
        "\n",
        "REPO_DIR_NAME=\"deep-learning-puzzle-project\"\n",
        "\n",
        "rm -r ${REPO_DIR_NAME}\n",
        "\n",
        "git clone https://github.com/silviasuhu/deep-learning-puzzle-project.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Move to the root directory of the repo to get consistency between Colab and local executions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "current_dir = os.path.basename(os.getcwd())\n",
        "print(current_dir)\n",
        "\n",
        "if current_dir == \"deep-learning-puzzle-project\":\n",
        "    print(\"You are already on the root directory of the 'deep-learning-puzzle-project' repo.\")\n",
        "\n",
        "else:\n",
        "  if IN_COLAB:\n",
        "    %cd \"deep-learning-puzzle-project\"\n",
        "  else:\n",
        "    %cd \"..\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageFile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import einops\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset download\n",
        "\n",
        "Download the dataset only if this notebook runs in Colab, otherwise you'll need to download it manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"IN_COLAB\"] = \"1\" if IN_COLAB else \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Assuming that we are on the root directory of the repo\n",
        "DATASET_PATH=\"data/CelebA-HQ\"\n",
        "\n",
        "os.environ[\"DATASET_PATH\"] = DATASET_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "if [ \"$IN_COLAB\" == \"0\" ]; then\n",
        "  echo \"Skipping download (IN_COLAB is false)\"\n",
        "  exit 0\n",
        "fi\n",
        "\n",
        "echo 'Downloading dataset...'\n",
        "\n",
        "OUTPUT_FILENAME='dataset.zip'\n",
        "FOLDER_NAME='CelebAMask-HQ'\n",
        "\n",
        "mkdir -p ${DATASET_PATH}\n",
        "\n",
        "if [ -d ${DATASET_PATH}/${FOLDER_NAME} ]; then\n",
        "  echo \"Skipping the download since the folder ${DATASET_PATH}/${FOLDER_NAME} already exists\"\n",
        "  exit 0\n",
        "fi\n",
        "\n",
        "rm ${OUTPUT_FILENAME}\n",
        "rm -r ${FOLDER_NAME}\n",
        "wget --no-check-certificate 'https://huggingface.co/datasets/liusq/CelebAMask-HQ/resolve/main/CelebAMask-HQ.zip?download=true' -O ${OUTPUT_FILENAME}\n",
        "echo \"${OUTPUT_FILENAME} downloaded. Unziping it...\"\n",
        "unzip ${OUTPUT_FILENAME}\n",
        "rm ${OUTPUT_FILENAME}\n",
        "\n",
        "mv ${FOLDER_NAME} ${DATASET_PATH}\n",
        "\n",
        "echo \"Done\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preview an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img = Image.open(DATASET_PATH + \"/CelebAMask-HQ/CelebA-HQ-img/1000.jpg\")\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the txt files from the DiffAssemble repository that define the data split between training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "if [ \"$IN_COLAB\" == \"0\" ]; then\n",
        "  echo \"Skipping download (IN_COLAB is false)\"\n",
        "  exit 0\n",
        "fi\n",
        "\n",
        "[ -f CelebA-HQ_test.txt ] && rm CelebA-HQ_test.txt\n",
        "[ -f CelebA-HQ_train.txt ] && rm CelebA-HQ_train.txt\n",
        "\n",
        "wget -q https://raw.githubusercontent.com/IIT-PAVIS/DiffAssemble/refs/heads/release/datasets/data_splits/CelebA-HQ_test.txt\n",
        "wget -q https://raw.githubusercontent.com/IIT-PAVIS/DiffAssemble/refs/heads/release/datasets/data_splits/CelebA-HQ_train.txt\n",
        "\n",
        "mkdir -p $DATASET_PATH\n",
        "mv CelebA-HQ_test.txt $DATASET_PATH\n",
        "mv CelebA-HQ_train.txt $DATASET_PATH\n",
        "\n",
        "ls $DATASET_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's tell to this notebook that we may need to import python packages from the 'src' folder\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"src\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataset_celeb_rot import CelebA_DataSet\n",
        "from puzzle_dataset import Puzzle_Dataset_ROT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = CelebA_DataSet(path=DATASET_PATH, train=True)\n",
        "img = dataset[0]\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect the output of Puzzle_Dataset_ROT\n",
        "\n",
        "###Interesting points\n",
        "\n",
        "- **Number of patches**. We'll see the image has been splited accordingly with the value assigned to the 'patch_per_dim' parameter. For instance, if patch_per_dim is [(6,6)], we'll see 36 patches per image.\n",
        "\n",
        "- **Rotation**.\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dt = CelebA_DataSet(DATASET_PATH, train=True)\n",
        "\n",
        "puzzle_dt = Puzzle_Dataset_ROT(dataset=train_dt,patch_per_dim=[(6,6)], augment=False, degree=-1, unique_graph=None, all_equivariant=False, random_dropout=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "elem=puzzle_dt[0]\n",
        "\n",
        "print(elem)\n",
        "print(f\"X: {elem.x}\")\n",
        "print(f\"EDGE_INDEX: {elem.edge_index}\")\n",
        "print(f\"INDEXES: {elem.indexes}\")\n",
        "print(f\"ROT: {elem.rot}\")\n",
        "print(f\"ROT_INDEX: {elem.rot_index}\")\n",
        "print(f\"IND_NAME: {elem.ind_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print original image\n",
        "idx = 0\n",
        "\n",
        "plt.imshow(puzzle_dt.dataset[idx])\n",
        "plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "graph=puzzle_dt[idx]\n",
        "\n",
        "# rotIdx=3\n",
        "# patches = graph.patches[:, rotIdx]\n",
        "\n",
        "grid = make_grid(graph.patches, nrow=6, padding=2)\n",
        "\n",
        "# Convert CHW -> HWC for matplotlib\n",
        "grid = grid.permute(1, 2, 0)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(grid)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's inspect the Dataloader too.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = Puzzle_Dataset_ROT(dataset=train_dt, patch_per_dim=[(6,6)], augment=False, degree=-1, unique_graph=None, all_equivariant=True, random_dropout=False)\n",
        "\n",
        "BATCH_SIZE=10\n",
        "dataloader = torch_geometric.loader.DataLoader(\n",
        "  dataset, batch_size=BATCH_SIZE, shuffle=True\n",
        ")\n",
        "\n",
        "first_batch = next(iter(dataloader))\n",
        "\n",
        "# Let's compare the dataset structure with the dataloader batch structure\n",
        "print(dataset[0])\n",
        "print(first_batch)\n",
        "\n",
        "# As you'll see, the first dimension of each parameter has been multiplied by the batch_size.\n",
        "\n",
        "# x contains...\n",
        "# edge_index contains...\n",
        "# indexes contains...\n",
        "# rot contains...\n",
        "# rot_index contains...\n",
        "# patches contains the image patches rotated 0,90,180 or 270 degrees\n",
        "# ind_name contains...\n",
        "# patches_dim contains the number of patches in the x and in the y axis.\n",
        "# batch contains...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "STEPS=10\n",
        "BATCH_SIZE=10\n",
        "EPOCHS=100\n",
        "PUZZLE_SIZES=\"6\"\n",
        "\n",
        "args=()\n",
        "\n",
        "args+=(\"-batch_size=$BATCH_SIZE\")\n",
        "args+=(\"-steps=$STEPS\")\n",
        "args+=(\"-epochs=$EPOCHS\")\n",
        "args+=(\"-puzzle_sizes=$PUZZLE_SIZES\")\n",
        "\n",
        "if [ \"$WANDB_DISABLED\" == \"true\" ]; then\n",
        "    args+=(\"-wandb_disabled\")\n",
        "fi\n",
        "\n",
        "echo \"ARGS: ${args[@]}\"\n",
        "\n",
        "pushd ${REPO_DIR}\n",
        "# python src/train_script.py -wandb_disabled\n",
        "python src/train_script.py \"${args[@]}\"\n",
        "popd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
